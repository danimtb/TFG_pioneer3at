\chapter{Desarrollo del proyecto}

En esta capítulo se expone cuál ha sido el planteamiento del proyecto y los pasos que se han seguido para conseguir los objetivos y llegar a unos resultados óptimos.

\section{Planteamiento}
El robots sobre el que se pretende trabajar es el Pioneer 3 AT, de la empresa Adept Mobile Robots, cuyas características se detallarán más adelante. La configuración del sistema motriz es de tipo skid-steer y será determinante a la hora de realizar el control del desplazamiento.

Para realizar la teleoperación del robot, utilizaremos las herramientas de comunicación de ROS, que hacen que la ejecución de los diferentes nodos de forma distribuida entre equipos se realice de forma transparente para el usuario. Con esta caracterítica podremos desarrollar con facilidad un sistema de telecontrol sin preocuparnos en exceso por la implementación de la comunicación entre equipos.

Para la navegación se pretende que el robot base sus movimientos en un sistema reactivo, es decir, que el robot base su navegación principalmente en la información captada por sus sensores y no en un mapa preestablecido. El control en navegación del robot se basará en la funcionalidad "Navigation Stack" de ROS, que también será explicada en detalle más delante.

El desarrollo principal para la navegación se basa en la infomación aportada por el sensor Kinect, sin embargo, el sensor láser proporciona una información muy potente para robots y también ha sido incluido en el dasarrollo de este proyecto, utilizándolo en conjunto con el sensor Kinect.

Seguidamente, se han realizado los ajustes pertinentes en la navegación del robot, para la cual se ha seguido el concepto de mapas de coste y descomposición en celdas. También se ha valorado la disposición de ambos sensores para capturar el entorno, así como el tratamiento dispar de los datos capturados por cada uno de ellos. De esta forma logramos que no se produzcan detecciones de objetos de manera duplicada y que no haya discrepancias entre los obstáculos que detecta un sensor respecto al otro \footnote{De especial interés en la icorporación de obstáculos al mapa mediante el uso de Costmaps en el sistema de navegación de ROS}.

Finalmente, se han incorporado características adicionales que aportan valor al desarrollo del proyecto, como el uso del simulador Gazebo o la interacción con el robot mediante comandos de voz y sintetizado de voz.

\section{Planificación del proyecto}

En este apartado se desarrollan las fase por las que ha pasado ete proyecto y realizaremos un análisis de tiempos.

Fase inicial: Familiarización con el entrono ROS y elección de herramientas.

\begin{enumerate}[i.]
  \item Utilizaremos las herramientas proporcionadas por ROS para evaluar los datos que pueda manejar el robot: RViz, rqt\_grapth, map\_server, rostopics...
  
  \item Para el control del movimiento del robot utilizaremos el nodo RoSAria debido a sus amplias posibilidades.
  
  \item Para acceder a la información de la Kinect utilizaremos los driver libfreenect, por ser librerías de código libre y utilizadas ampliamente.
\end{enumerate}

Segunda fase: Realización del nodo de teleoperación y comunicación entre equipos conectados a la misma red.

\begin{enumerate}[i.]
  \item Utilizamos la configuración de equipos en red para acceder a la información publicada por nodos que se ejecuten en varias máquinas **referencia**
  
  \item Partindo del nodo de teleoperacion de "Turtlesim" *refrencia*, realizamos un nodo similar para nuestro robot.
\end{enumerate}

Tercera fase: Incorporación de los sensores al robot y acceso a los datos.

\begin{enumerate}[i.]
  \item Para el sensor Kinect, realizamos un adaptador para conectarlo a la alimetnación del robot. Utilizando el nodo "freenect\_stack" *REFERENCIA*, accedemos a la nube de puntos y la imagen.
  
  \item Utilizamos el nodo LMS1xx **Referencia** para la puesta en marcha del láser y el acceso a los datos.
  
  \item Incorporación de sistemas de referencia "base\_link", "laser", ''camera\_link'' y sus transformadas mediante el paquete "tf" **referencia**. 
  
  \item Visualización del conjunto de datos junto con los ejes de referencia en RViz.
\end{enumerate}

Cuarta fase: Incorporación del sistema de navegación y ajuste de los parámetros

\begin{enumerate}[i.]
  \item Calibrado de los encoders de las ruedas del robot y ajuste de la odometría mediante RosAria.
  
  \item Incorporación del sistema de navegación ROS de forma básica.
  
  \item Navegación utilizando el sensor Kinect y el sensor Sick y generado de mapas mediante "slam\_gmapping".
  
  \item Ajuste de los planeadores de taryectoria del robot y parámetros de giro y control.
\end{enumerate}

Quinta fase: Ajuste de la navegación y simulación mediante gazebo

\begin{enumerate}[i.]
  \item Navegación en modo global (utilizando un mapa guardado) y en modo local (completamente reactivo).
  
  \item Puesta en marcha del simulador Gazebo y configuración del robot en el entorno.
  
  \item Disposición de los sensores de manera óptima y remodelado de la estructura física del robot.
\end{enumerate}

Sexta fase: Nuevas funcionalidades y toma de datos.

\begin{enumerate}[i.]
  \item Incorporación de la funcionalidad "follower", adaptada a partir del robot Turtlebot **Refeencia**, para el guiado del robot.
  
  \item Interfaz de comandos por voz y sintetizador de texto a voz.
  
  \item Pruebas físicas, recogida y análisis de los datos.
\end{enumerate}


Análisis de tiempos:

\newgantttimeslotformat{stardate}{%
	\def\decomposestardate##1.##2\relax{%
		\def\stardateyear{##1}\def\stardateday{##2}%
	}%
	\decomposestardate#1\relax%
	\pgfcalendardatetojulian{\stardateyear-01-01}{#2}%
	\advance#2 by-1\relax%
	\advance#2 by\stardateday\relax%
}
\begin{ganttchart}[hgrid, vgrid,time slot format=stardate]{2014.265}{2014.297}
	\gantttitlecalendar{year, month=name, week}\\
\end{ganttchart}

\section{Tecnologías y herramientas empleadas en el proyecto}

ROS

gazebo

c++

python

controlador de versiones: git - github

pointcloud library

\section{Hardware}
En esta parte se explica detalladamente el hardware empleado en el desarrollo del proyecto.

\subsection{Pioneer 3 AT}

El robot Pioneer 3 AT (Figura \ref{fig:pioneer3at}), perteneciente a la empresa Adept MobileRobots, es un robot de cuatro ruedas en configuración skid-steer y todo terreno (AT, All Terrain) de operación e investigación en laboratorio.\\

\begin{figure}[htp]
\centering
\includegraphics[width=0.4\textwidth]{figuras/pioneer_3_at.jpg}
\caption{Robot Pioneer 3-AT} \label{fig:pioneer3at}
\end{figure}

Su configuración en skid-steer permite un control relativamente simple utilizando el modo diferencial para poder realizar giros con gran maniobrabilidad, sin embargo, esta configuración depende mucho del tipo de suelo, con lo que se pierde precisión.

Este robot dispone de baterías, interruptor con parada de emergencia, dos motores de corriente continua para cada par de ruedas con transmisión mediante correa, encoders para leer la odometría y un microcontrolador con firmware ARCOS.

Ademas cuenta con un pequeño computador interno conectado al microcontrolador que puede utilizarse para realizar operaciones de manera autónoma.

El cuerpo del robot es de aluminio y su parte delantera así como superior es fácilmente desmontable para realizar las conexiones pertinentes y acceder al ordenador de a bordo y la placa microcontroladora. En la plataforma superior se sitúa el panel de control (Figura \ref{fig:panel_control})para acceder al ordenador de abordo conectando un monitor, teclado y ratón, puerto serial RS-232, botones de encendido y reset varios leds indicadores de estado y de envío y recepción de datos.

\begin{figure}[htp]
\centering
\includegraphics[width=0.6\textwidth]{figuras/panel_control.png}
\caption{Panel de control del robot Pioneer 3-AT} \label{fig:panel_control}
\end{figure}

En la siguiente tabla (Tabla \ref{tabla_pioneer3at}) se describen las principales características del robot.

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{c c}
\hline
{\bf Especificaciones} & {\bf Pioneer 3 AT} \\ \hline
Largo & 508 mm \\
Ancho & 497 mm \\
Alto & 277 mm \\
Distancia al suelo & 80 mm \\
Peso & 12 kg \\
Carga útil & 32 kg \\
Cuerpo & Aluminio de 1.6 mm \\
Baterías & 3 de 12 V ~Ah, estancas, plomo-ácido \\
Autonomía & 4-8 horas \\
Sistema motriz & 4 ruedas motrices \\
Ruedas & Neumáticos de Nylon \\
Diámetro de rueda & 222 mm \\
Ancho de rueda & 88 mm \\
Sistema de giro & Diferencial \\
radio máxima curvatura & 40 cm \\
Radio de giro & 0 cm \\
Máxima velocidad de avance & 1.2 m/s \\
Máximo escalón & 10 cm \\
Máximo hueco & 15.2 cm \\
Terreno & Asfalto, Tierra, Césped, etc. \\
Encoders & 500 pulsos \\
Procesador & Hitachi H8S \\ \hline
\end{tabular}
}
\caption{Especificaciones del robot Pioneer 3 AT}
\label{tabla_pioneer3at}
\end{table}


\subsection{Sensor Kinect}

Kinect es un conjunto de sensores de bajo coste que lo convierte en una
herramienta excepcional (Figura \ref{fig:sensor_kinect}). Este dispositivo incluye una cámara de vídeo RGB, una cámara infrarroja de profundidad, un array de micrófonos y altavoces, un acelerómetro y un pequeño motor que le permite hacer movimientos de inclinación.

\begin{figure}[htp]
\centering
\includegraphics[width=0.6\textwidth]{figuras/sensor_kinect.png}
\caption{Sensor Kinect}
\label{fig:sensor_kinect}
\end{figure}

Su función principal es la de percibir el entorno captando una serie de puntos que se ubican en las tres dimensiones. Su funcionamiento a grandes rasgos se basa en un emisor de infrarrojos a 830 nm que interactñua con los objetos y una cámara infrarroja que etecta la diferencia entre la proyección anterior y la actual, obteniendo la distancia a cada objeto.

En primer lugar, el laser infrarrojo es emitido por Kinect con un patrón
determinado (Projected textures **REFERENCIA**), el cual no es simétrico sino que tiene puntos aleatorios que se dispersa gracias a unas lentes de proyección. Estos puntos aleatorios se reflejan en los objetos, los cuales sería posible verlos con una cámara externa.

A continuación, al sensor de Kinect MT9M001C12STM, que no es más que el
sensor CMOS de una cámara en la que se le trata para que observe solo el
infrarrojo, obteniendo los puntos infrarrojos en el plano 2D. El motivo por el que podemos medir la profundidad de los objetos (su distancia) es porque sabemos el patrón de cómo emite el laser emisor \cite{konolige2010projected}, por tanto sabremos que si un punto no está en el sitio que corresponde, se ha trasladado respecto al punto inicial y se le aplica la correspondiente transformación (Figura \ref{fig:proyecciones_kinect}), obteniendo finalmente los puntos de toda la nube en coordenadas cartesianas XYZ.\\

\begin{figure}[htp]
\centering
\includegraphics[width=0.8\textwidth]{figuras/proyecciones_kinect.png}
\caption{Proyección de infrarrojos y obtención de la nube de puntos}
\label{fig:proyecciones_kinect}
\end{figure}

La siguiente tabla (Tabla \ref{tabla_kinect}) muestra las especificaciones del sensor Kinect.

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c}
\hline
{\bf Especificaciones} & {\bf Sensor Kinect} \\ \hline
Dimensiones del conjunto & 270mm x 50mm x 70mm \\
Fuente infrarroja & 830nm \\
Potencia & 60 mW \\
Cámara Infrarroja & MT9M001C12STM \\
Resolución cámara infrarroja & 1200x960 pixeles \\
Frecuencia & 30 Hz \\
Tamaño pixel & 5.2um x 5.2um  \\
Pixeles activos & 1280H x 1024V \\
Campo de visión & 58º H, 45º V, 70º D \\
Resolución espacial & 3mm (a 2 metros de distancia) \\
Resolución de profundidad & 1cm (a 2 metros de distancia) \\
Distancia de operación & 0.45m ? 6.5m \\
Cámara RGB & MT9M112 \\
Resolución cámara RGB & 640 x 480) \\
Audio & TAS1020B (Controlador de Audio) \\
Formato & 16kHz, 16-bit mono, modulación por
codificación de pulso (PCM)\\
Entrada de audio & 4 micrófonos con conversión analógico
digital de 24bits \\
Acelerómetro & KXSD9-2050\\ \hline
\end{tabular}
}
\caption{Características del sensor Kinect}
\label{tabla_kinect}
\end{table}

\subsection{Láser SICK LMS100}

Aunque el planteamiento incial del proyecto planteaba la navegación basada únicamente en el sensor kinect, debemos mencionar el uso del sensor láser Sick LMS100 (Figura \ref{fig:sensor_sicklms100}).

\begin{figure}[htp]
\centering
\includegraphics[width=0.6\textwidth]{figuras/SICK_LMS100.jpg}
\caption{Sensor escaner láser Sick LMS100}
\label{fig:sensor_sicklms100}
\end{figure}

Este es un sensor láser por infrarrojos de clase I (Inofensivo para el ojo humano), que obtiene la medida de distancias con gran preción y rapidez en un solo plano y realizando un barrido de 270º (Figura \ref{fig:sicklms100_rango}).

\begin{figure}[htp]
\centering
\includegraphics[width=0.6\textwidth]{figuras/sicklms100_rango.png}
\caption{Campo de visión del sensor láser Sick LMS100} \label{fig:sicklms100_rango}
\end{figure}

Este sensor está colocado en la parte trasera del robot, enfocando hacia atrás para cubrir un mayor rango y conocer todo el entorno alrededor del robot.

En la siguiente tabla (Tabla \ref{tabla_sicklms100}) se recogen sus características principales.

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c}
\hline
{\bf Especificaciones} & {\bf Sick LMS100} \\ \hline
Campo de aplicación & Interno \\
Fuente infrarroja & 905 nm \\
Clase Láser & 1 (IEC 60825-1) \\
Campo de visión & 270º \\
Frecuencia de escaneo & 25Hz/50Hz \\
Resolución angular & 0.25º/0.5º \\
Distancia de operación & 0.05 - 20 m  \\
Tiempo de respuesta & 20 ms \\
Error & 30 mm \\
Interfaz de datos & Ethernet \\
Tensión de operación & 10.8V - 20V DC \\
Consumo & 20 W \\
Peso & 1.1 Kg \\
Dimensiones & 105mm x 102mm x 152mm\\ \hline
\end{tabular}
}
\caption{Características del sensor láser Sick LMS100. Basado en \cite{sicklms100}}
\label{tabla_sicklms100}
\end{table}

\subsection{Intel NUC NUC5i7RYH}

El ordenador Intel NUC NUC5i7RYH, es un ordenador de altas prestaciones y de tamaño compacto que ofrece unas buenas características para procesar datos y realizar la algoritmia adecuada para tareas de robótica.

Está equipado con un procesador Intel i7-5557U de quinta generación que ofrece una frecuencai de reloj de 3.1 GHz. Está incorporado con un discoduro de estado sólido que permite una alta velocidad de lectura y escritura en disco, así como una tarjeta RAM de tipo DDR3L de 8GB que permitirá el intercambio de información entre los nodos ROS de una manera fluida.

Su cometido será el de procesar la información de los sensores, generar los mapas incorporando los obstáculos, generar las trayectorias de navegación y comandar los motores del robot para realizar movimientos.

Dispone de tamaño compacto y un consumo bajo, juto con una alimentación a partir de los 12 voltios, lo que lo hace ideal para incorporarlo en robots móviles que requieran realizar tareas sin depender de una infraestructura.

En la tabla \ref{tabla_intelnuc} pueden consultarse sus características principales.

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c}
\hline
{\bf Especificaciones} & {\bf Intel NUC NUC5i7RYH} \\ \hline
Procesador & Intel Core i7-5557U, dual-core \\
Frecuencia de reloj & 3.1 GHz hasta 3.4 GHz \\
Memoria RAM & DDR3L1 **DATO** \\
Disco duro & M.2 SSD **DATO** \\
Gráficos & Iris Graphics 6100 \\
Conectividad de periféricos & 2 x USB 3.0 en el panel posterior\\
 & 2 x USB 3.0 en el panel frontal\\
 & 2 x USB 2.0 internos vía colector\\
Conectividad de red & Intel 10/100/1000 Mbps\\
 & Intel® Wireless-AC 7265 M.2, antenas inalámbricas (IEEE 802.11ac)\\
Alimentación & 12-19V DC \\
Consumo & 65 W \\
Dimensiones & 115mm x 111mm x 48.7mm\\ \hline
\end{tabular}
}
\caption{Características del ordenador Intel NUC NUC5i7RYH}
\label{tabla_intelnuc}
\end{table}