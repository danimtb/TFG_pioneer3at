\chapter{Control primario}

En este capítulo se realiza una primera aproximación al control del robot y a los nodos básicos que deben ejecutarse para controlarlo y acceder a la información de los sensores.

\section{Nodos de bajo nivel}

Los nodos necesarios para el control del robot requieren el acceso a los motores y a la lectura de la odometría. También es necesario disponer de controladores para ambos sensores utilizados y que su información se publique en tipos de datos reconocibles por ROS. Los nodos utilizados para estos dispositivos hardware se describen a continuación. 

\subsection{Control del robot: Rosaria y p2os} \label{subsection:rosaria}

Como hemos indicado anteriormente, la librería que nos proporciona el acceso a la placa controladora de nuestro robot Pioneer es Aria. Esta librería es la que proporciona Adept Mobile Robots para realizar el control completo del robot y acceder a sus parámetros con figurables.

Los paquetes disponibles en ROS para el control de los robots de la familia Pioneer son dos, por un lado tenemos Rosaria y por otro p2os.

p2os **referencia** es un paquete que agrupa conjunto de utilidades y nodos desarrollados para controlar el robot. Su característica principal es que accede de manera nativa a la placa controladora del robot y no dependen de la librería Aria. Además incorpora funcionalidades configuradas como modelos 3D de robot, simulación con Gazebo o la configuración de la navegación.

Sin embargo, p2os no integra todas las funcionalidades a las que tiene acceso Aria como son la reconfiguración de los parámetros de la odometría.

Rosaria **referencia** es un nodo de interfaz entre ROS y Aria, por tanto incluye todas prácticamente todas las funcionalidades de esta. Podemos acceder a la calibración de los encoders de la odometría así como conectar con el simulador MobileSim (ver sección \ref{MobileSim})

A continuación se muestra el launchfile para ejecutar el nodo RosAria:

\begin{code}[htp]
\begin{lstlisting}[style=launch]
<launch>
<!-- Starting rosaria driver for motors and encoders -->
  <node name="rosaria" pkg="rosaria" type="RosAria" args="_port:=/dev/ttyUSB0">
  <rosparam>
      TicksMM: 166
      RevCount: 37350
      DriftFactor: 0
  </rosparam>
  <remap from="~cmd_vel" to="cmd_vel"/>
  </node>
</launch>
\end{lstlisting}
\hypersetup{urlcolor=black}
Fuente: \href{https://github.com/danimtb/pioneer3at_ETSIDI/blob/master/pioneer_utils/sensors/rosaria.launch}{\textit{ pioneer\_utils/sensors/rosaria.launch}}
\hypersetup{urlcolor=blue}
\caption{Launchfile para RosAria.}
\end{code}

Como puede verse, podemos modificar los valores usados por Aria para realizar el cómputo de la odometría (más información la subsección \ref{subsection:odometria} del apéndice).

En la tabla \ref{tabla_rosaria} se muestra parte de la API utilizada de rosaria.

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c}
& {\bf RosAria API} & \\
{\bf Topics suscritos} & {\bf Mensaje} & {\bf Descripción}\\ \hline
cmd\_vel & geometry\_msgs/Twist & Recibe los comandos de velocidad\\
{\bf Topics publicados} & {\bf Mensaje} & {\bf Descripción}\\
\hline
pose & nav\_msgs/Odometry & Publica la odometría\\
{\bf Parámetros} & {\bf Tipo} & {\bf Descripción}\\
\hline
port & string & Puerto serie del robot\\
TicksMM & float & Calibración de la odometría\\
DriftFactor & float & Rozamiento de la odometría\\
RevCount & float & Calibración de los encoders\\
{\bf Frames publicados} &  & {\bf Descripción}\\
\hline
base\_link & & Referencia base del robot\\
odom & & Referencia odométrica
\end{tabular}
}
\caption{API de rosaria utilizada. Basado en \cite{rosaria}}
\label{tabla_rosaria}
\end{table}

\subsection{Sensor Kinect}\label{subsection:kinect}

Para la puesta en marcha del sensor Kinect existen en ROS diferentes paquetes que utilizan una u otra librería de código en función de quién haya lo haya desarrollado.

Existen dos paquetes destinados al control del sensor Kinect:

Por un lado tenemos openni\_kinect **referencia**, que utiliza los drivers originales desarrollados por la empresa PrimeSense encargada de fabricar este dispositivo. Este paquete y en concreto los drivers del dispositivo han sido utilizados ampliamente tanto en desarrollos realizados con ROS como fuera de este entorno. Sus características principales son la total funcionalidad, aprovechamiento de toda la tecnología de este sensor y capacidad para monitorear la posición del esqueleto de una persona. Sin embargo, desarrollo del paquete openni\_kinect solo se mantuvo activo hasta a versión de ROS Fuerte **referencia** debido a la compra de PrimeSense por la conocida marca de informática Apple **referencia**.

Por otro lado, gracias al gran desarrollo software llevado a cabo por la comunidad OpenSource, disponemos de los divers libfreenect desarrollados por el proyecto OpenKinect \url{http://openkinect.org/wiki/Main_Page} que trata de ofrecer una vía alternativa para controlar el sensor de Microsoft. Estos drivers se encapsulan y adaptan su interfaz a ROS a través del paquete freenect\_stack **referencia** el cual nos ofrece acceso tan solo a la imagen y la nube de puntos del sensor. Su integración no es completa, no dispone de características adicionales como el monitoreo de la posición de una persona, sin embargo su funcionamiento es correcto y está adaptado a ROS en su versión Indigo y esto nos ofrece la posibilidad de integrarlo en nuestro sistema. Por estas razones ha sido el software utilizado para acceder al sensor Kinect en este proyecto.

freenect\_stack, al ser un paquete de terceros, debe clonarse desde su repositorio de código fuente e incorporarlo a nuestro entorno catkin.

Su puesta en marcha es bastante inmediata y podemos hacer uso de los launch files que ofrece freenect\_launch desde consola de la siguiente forma:

\begin{code}[htp]
\begin{lstlisting}[style=consola]
roslaunch freenect_launch freenect.launch
\end{lstlisting}
\hypersetup{urlcolor=black}
Fuente: \href{https://github.com/ros-drivers/freenect_stack/blob/master/freenect_launch/launch/freenect.launch}{\textit{freenect\_stack/freenect\_launch/launch/freenect.launch}}
\hypersetup{urlcolor=blue}
\caption{Launchfile para Kinect en el paquete freenect\_launch.}
\end{code}

En la tabla \ref{tabla_freenect} se muestra parte de la API utilizada.

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c}
& {\bf libfreenect\_stack API} & \\
{\bf Topics publicados} & {\bf Mensaje} & {\bf Descripción}\\
\hline
camera/depth/points & sensor\_msgs/PointCloud2 & Publica la nube de puntos\\
camera/depth/image\_raw & sensor\_msgs/Image & Imagen captada\\
camera/depth/camera\_info & sensor\_msgs/CameraInfo & Información de la cámara\\
{\bf Frames} &  & {\bf Descripción}\\
\hline
camera\_link & & Referencia base de Kinect\\
camera\_rgb\_frame & & Referencia cámara RGB\\
camera\_depth\_frame & & Referencia cámara IR\\
\end{tabular}
}
\caption{API de freenect\_stack utilizada.}
\label{tabla_freenect}
\end{table}

\subsection{Sensor Láser Sick LMS100}\label{subsection:sicklms100}

Existe un amplio soporte para sensores láser de la marca Sick, entre ellos el más popular es la familia Sick LMS200 ya que se utiliza en muchos desarrollos relacionados con la robótica móvil **referencia**. Esa familia de sensores utiliza una interfaz de comunicación en serie a través de puerto RS-232, sin embargo, la familia de dispositivos Sick LMS100 utiliza interfaz ethernet y requiere un tratamiento de datos diferente.

El láser Sick LMS100 ha sido integrado en ROS y utilizado en este proyecto ya que se había dado uso en proyectos anteriores **referencia alejandro** y se consideró conveniente incorporarlo y utilizarlo para obtener una navegación más precisa del robot.

Para acceder al sensor Sick LMS100 utilizamos el paquekte LMS1xx desarrollado por Clearpath Robotics **referencia** que se basa en el trabajo de otros dos desarrolladores de la comunidad ROS, y en concreto en los drivers desarrollados por **referencia** https://github.com/konradb3/libLMS1xx

El paquete LMS1xx consta de un solo nodo que se conecta a través de una IP indicada como parámetro. Su uso es sencillo mediante un archivo launchfile y tan solo debemos tener la precaución de configurar correctamente la IP manual del puerto ethernet de nuestro ordenador.

\begin{code}[htp]
\begin{lstlisting}[style=launch]
<launch>
  <arg name="host" default="192.168.1.14" />
  <node pkg="lms1xx" name="lms1xx" type="LMS1xx_node">
    <param name="host" value="$(arg host)" />
  </node>
</launch>
\end{lstlisting}
\hypersetup{urlcolor=black}
Fuente: \href{https://github.com/clearpathrobotics/LMS1xx/blob/master/launch/LMS1xx.launch}{\textit{LMS1xx/launch/LMS1xx.launch}}
\hypersetup{urlcolor=blue}
\caption{Launchfile para el sensor Láser Sick LMS100.}
\end{code}

Pueden precisarse algunos ajustes previos con la herramienta que ofrece el fabricante "SOPAS Engineering tool", los cuales pueden encontrarse en el apéndice de este trabajo (Sección \ref{subsection:sicklms100_apendice}).

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c}
& {\bf LMS1xx API} & \\
{\bf Topics publicados} & {\bf Mensaje} & {\bf Descripción}\\
\hline
/scan & sensor\_msgs/LaserScan & Puntos láser\\
{\bf Parámetros} & {\bf Tipo} & {\bf Descripción}\\
\hline
host & string & Dirección IP del láser\\
{\bf Frames} &  & {\bf Descripción}\\
\hline
laser & & Centro del haz láser\\
\end{tabular}
}
\caption{API de LMS1xx utilizada.}
\label{tabla_lms1xx}
\end{table}

\url{http://wiki.ros.org/LMS1xx}

\subsection{Integración del hardware}\label{subsection:integracion_hardware}

Una vez disponemos de todos los paquetes necesarios para poner en funcionamiento todo el hardware en el robot, necesitamos integrar todos los nodos bajo una misma configuración y definir mediante transformadas la posición de los sensores en el robot.

Es necesario por tanto crear un nuevo archivo launchfile (Código \ref{code:pioneer3at-rosaria})desde el cual lanzar cada nodo con las configuraciones del hardware y definir transformadas estáticas entre cada uno de los \textit{frames}.

\begin{code}[htp]
\begin{lstlisting}[style=launch]
<launch>

<!-- Launching p2os RobotModel --> OJO!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  <include file="$(find p2os_urdf)/launch/pioneer3at_urdf.launch"/>

<!-- Launching LMS1xx_node for laser Sick LMS100 via ethernet -->
  <include file="$(find pioneer_utils)/sensors/LMS1xx.launch"/>

<!-- start sensor-->
<include file="$(find freenect_launch)/launch/freenect.launch"/>

<!-- Launch kinect and depthimage_to_laser node -->
  <include file="$(find pioneer_utils)/sensors/kinect_to_laser_low.launch"/>

<!-- Launch kinect and depthimage_to_laser node -->
  <include file="$(find pioneer_utils)/sensors/kinect_to_laser.launch"/>

<!-- Starting rosaria driver for motors and encoders -->
  <include file="$(find pioneer_utils)/sensors/rosaria.launch"/>

  <node pkg="tf" type="static_transform_publisher" name="base_to_laser_broadcaster" args="-0.2 0 0.390 3.141592 0 0 base_link laser 1" />
  <node pkg="tf" type="static_transform_publisher" name="base_to_camera_broadcaster" args="0.020 0 0.375 0 0 0 base_link camera_link 1" />

</launch>
\end{lstlisting}
\hypersetup{urlcolor=black}
Fuente: \href{https://github.com/danimtb/pioneer3at_ETSIDI/blob/master/pioneer_utils/sensors/pioneer3at-rosaria.launch}{\textit{pioneer\_utils/sensors/pioneer3at-rosaria.launch}}
\hypersetup{urlcolor=blue}
\caption{Launchfile creado para robot Pioneer 3 AT.}
\label{code:pioneer3at-rosaria}
\end{code}

Como resultado, obtenemos una relación entre cada sistema de coordenadas (\textit{frame}) y podemos realizar cálculos entre cada uno de ellos. Esto también sirve para que el robot "sea consciente" de su configuración.

FIGURA VIEW FRAMES****

\section{Nodo de teleoperación}

Uno de los primeros objetivos de este proyecto es realizar el control teleoperado del robot. Utilizando ROS y sus características para operar de manera distribuida en diferentes máquinas, esta tarea se vuelve inmediata para el usuario.

ROS trabaja en forma de procesos que se ejecutan de manera independiente y se comunican a través del nodo principal o Máster con el paso de mensajes. Ya que el máster dispone de una dirección IP en la máquina que lo ejecuta, basta con indicar en el entorno ROS de cada máquina la dirección de este para que los nodos abran una comunicación con esa dirección IP.

Los pasos para configurar las máquinas bajo la misma red se describen con detalle en la guía ROS NETWORKING y consisten básicamente en indicar en el sript \textit{.bashrc} el parámetro ROS	\_IP y ROS\_MASTER\_URI.

ROS\_IP debe contener la IP que tenga nuestra máquina en la red que esté operando y ROS\_MASTER\_URI la dirección \textit{http} correspondiente de la máquina donde se ejecute el nodo principal.

\begin{code}[htp]
\begin{lstlisting}[style=launch]
export ROS_IP=10.42.0.1
export ROS_MASTER_URI=http://10.42.0.1:11311
\end{lstlisting}
Fuente: \textit{$\sim$/.bashrc}
\caption{Líneas del archivo \textit{.bashrc} en el ordenador de abordo.}
\end{code}

\begin{code}[!htp]
\begin{lstlisting}[style=launch]
export ROS_IP=10.42.0.77
export ROS_MASTER_URI=http://10.42.0.1:11311
\end{lstlisting}
Fuente: $\sim$\textit{/.bashrc}
\caption{Ejemplo \textit{.bashrc} en un ordenador externo para realizar comunicación con el máster.}
\end{code}

De esta manera podemos desarrollar un nodo ROS que se conecte al topic de RosAria que comanda los motores \textit{cmd\_vel} y publicar diferentes valores de velocidad en función de las teclas que se pulsen.

\begin{code}[htp]
\begin{lstlisting}[style=C++]	
}
\end{lstlisting}
Fuente: $\sim$\textit{/.bashrc}
\caption{Ejemplo \textit{.bashrc} en un ordenador externo para realizar comunicación con el máster.}
\end{code}

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c}
& {\bf teleop\_p3at API} & \\
{\bf Topics publicados} & {\bf Mensaje} & {\bf Descripción}\\ \hline
cmd\_vel & geometry\_msgs/Twist & Publica comandos de velocidad\\
\end{tabular}
}
\caption{API de teleop\_p3at}
\label{tabla_rosaria}
\end{table}

\section{Nodo de navegación estimada}

La navegación estimada, más conocida en inglés como Dead Reckoning \cite{deadreckoning}, es la capacidad para realizar navegación en un entorno basándonos solamente en la información que aportan los sensores de la odometría.

Es un método estimado de localización que se basa en la información de los encoders y no tiene en cuenta aspectos como el tipo de superficie, la inclinación, el rozamiento o incluso obstáculos que puedan frenar o modificar el desplazamiento del robot (a pesar de que sus ruedas giren).

Este nodo de navegación puede utilizarse para indicar al robot que avance cierta cantidad de metros y que realice giros a derecha o izquierda en un determinado ángulo.

**Fragmento de código**

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c}
& {\bf moving\_alone API} & \\
{\bf Topics suscritos} & {\bf Mensaje} & {\bf Descripción}\\ \hline
pose & nav\_msgs/Odometry & Recibe la odmetría\\
{\bf Topics publicados} & {\bf Mensaje} & {\bf Descripción}\\ \hline
cmd\_vel & geometry\_msgs/Twist & Publica comandos de velocidad\\
{\bf Frames suscritos} &  & {\bf Descripción}\\
\hline
base\_link & & Referencia base del robot\\
odom & & Referencia odométrica
\end{tabular}
}
\caption{API de moving\_alone}
\label{tabla_rosaria}
\end{table}

\section{Nodo de guiado (follower)}

El nodo de guiado se basa en el procesamiento de la nube de puntos obtenida a través de los nodos del paquete freenect\_stack.

El nodo está originalmente desarrollado para el robot Turtlebot pero es fácil adaptable a otros robots.

Requiere un Topic de tipo \textit{sensor\_msgs/PointCloud2} al que suscribirse para leer la nube de puntos y un topic de tipo \textit{geometry\_msgs/Twist} al que publicar los movimientos de giro, avance y retroceso.

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c}
& {\bf turtlebot\_follower API} & \\
{\bf Topics suscritos} & {\bf Mensaje} & {\bf Descripción}\\ \hline
camera/depth/points & sensor\_msgs/PointCloud2 & Recibe la nube de puntos\\
{\bf Topics publicados} & {\bf Mensaje} & {\bf Descripción}\\ \hline
cmd\_vel & geometry\_msgs/Twist & Publica comandos de velocidad\\
{\bf Parámetros} & {\bf Tipo} & {\bf Descripción}\\
\hline
min\_y & double & Posición mínima de puntos en Y\\
max\_y & double & Posición máxima de puntos en Y\\
min\_x & double & Posición mínima de puntos en X\\
max\_x & double & Posición máxima de puntos en Y\\
max\_z & double & Posición máxima de puntos en Y\\
goal\_z & double & Distancia mantenida en el seguimiento\\
z\_scale & double & Factor de escala velocidad trans.\\
x\_scale & double & Factor de escala en velocidad de rot.\\
enabled & bool & Hanilita los movimientos\\
\end{tabular}
}
\caption{API de turtlebot\_follower}
\label{tabla_rosaria}
\end{table}

El tratamiento de la nube de puntos se realiza con la librería PCL (PointCloud Library \cite{PCL}) y su funcionamiento es el siguiente:

\begin{enumerate}[1.-]
\item Busca puntos dentro de los límites establecidos.
\item Calcula las dimensiones de los puntos encontrados.
\item Calcula el centroide del la zona destacada.
\item Mueve el robot de manera acorde hasta que alcanza la distancia establecida.
\end{enumerate}

\begin{code}[!htp]
\begin{lstlisting}[style=launch]
<launch>
    
<!--  Load turtlebot follower into the 3d sensors nodelet manager to avoid pointcloud serializing -->
    <node pkg="nodelet" type="nodelet" name="turtlebot_follower" args="load turtlebot_follower/TurtlebotFollower camera/camera_nodelet_manager">
      <remap from="turtlebot_follower/cmd_vel" to="/cmd_vel"/>
      <remap from="depth/points" to="camera/depth/points"/>
      <param name="enabled" value="true" />
      <param name="x_scale" value="10.0" />
      <param name="z_scale" value="10.0" />
      <param name="min_x" value="-0.35" />
      <param name="max_x" value="0.35" />
      <param name="min_y" value="0.1" />
      <param name="max_y" value="0.5" />
      <param name="max_z" value="1.2" />
      <param name="goal_z" value="0.6" />
    </node>
</launch>
\end{lstlisting}
\hypersetup{urlcolor=black}
Fuente: \href{https://github.com/danimtb/pioneer3at_ETSIDI/blob/master/pioneer_utils/follower/simple-follower.launch}{\textit{pioneer\_utils/follower/simple-follower.launch}}
\hypersetup{urlcolor=blue}
\caption{Launchfile para turtlebot\_follower en el robot Pioneer 3 AT.}
\end{code}
