\chapter{Control a bajo nivel}

En este capítulo se realiza una primera aproximación al control del robot y a los nodos básicos que deben ejecutarse para controlarlo y acceder a la información de los sensores.

\section{Nodos Hardware}

Los nodos necesarios para el control del robot requieren el acceso a los motores y a la lectura de la odometría. También es necesario disponer de controladores para ambos sensores utilizados y que su información se publique en tipos de datos reconocibles por ROS. Los nodos utilizados para estos dispositivos hardware se describen a continuación. 

\subsection{Control del robot: Rosaria y p2os} \label{subsection:rosaria}

Como hemos indicado anteriormente, la librería que nos permite el acceso a la placa controladora de nuestro robot Pioneer es Aria. Esta librería es la que proporciona Adept Mobile Robots para realizar el control completo del robot y acceder a sus parámetros configurables.

Los paquetes disponibles en ROS para el control de los robots de la familia Pioneer son dos, por un lado tenemos Rosaria y por otro p2os.

\begin{itemize}
\item \textbf{p2os} **referencia** es un paquete que agrupa un conjunto de utilidades y nodos desarrollados para controlar el robot. Su característica principal es que accede de manera nativa a la placa controladora del robot por lo que no depende de la librería Aria. Además incorpora funcionalidades adicionales como modelos 3D de robot, simulación con Gazebo o la configuración de la navegación.

Sin embargo, \textit{p2os} no integra todas las funcionalidades a las que tiene acceso Aria como es la reconfiguración de los parámetros de la odometría.

\item \textbf{Rosaria} **referencia** es un nodo de interfaz entre ROS y Aria, por tanto incluye todas prácticamente todas las funcionalidades de esta. Podemos acceder a la calibración de los encoders de la odometría así como conectar con el simulador \textit{MobileSim} (ver sección \ref{MobileSim}).

A continuación se muestra el \textit{launchfile} para ejecutar el nodo \textit{RosAria}:

\begin{code}[htp]
\begin{lstlisting}[style=launch]
<launch>
<!-- Starting rosaria driver for motors and encoders -->
  <node name="rosaria" pkg="rosaria" type="RosAria" args="_port:=/dev/ttyUSB0">
  <rosparam>
      TicksMM: 166
      RevCount: 37350
      DriftFactor: 0
  </rosparam>
  <remap from="~cmd_vel" to="cmd_vel"/>
  </node>
</launch>
\end{lstlisting}
\hypersetup{urlcolor=black}
Fuente: \href{https://github.com/danimtb/pioneer3at_ETSIDI/blob/master/pioneer_utils/sensors/rosaria.launch}{\textit{ pioneer\_utils/sensors/rosaria.launch}}
\hypersetup{urlcolor=blue}
\caption{Launchfile para RosAria.}
\end{code}

Como puede verse, podemos modificar los valores usados por Aria para realizar el cómputo de la odometría (más información la subsección \ref{subsection:odometria} del apéndice).

Como cualquier nodo en ROS, el nodo \textit{RosAria} publicará una serie de Topics y se suscribirá a otros para poder intercambiar información entre otros nodos. En la tabla \ref{tabla_rosaria} se muestra parte de la API utilizada de rosaria.

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c}
& {\bf RosAria API} & \\
{\bf Topics suscritos} & {\bf Mensaje} & {\bf Descripción}\\ \hline
cmd\_vel & geometry\_msgs/Twist & Recibe los comandos de velocidad\\
{\bf Topics publicados} & {\bf Mensaje} & {\bf Descripción}\\
\hline
pose & nav\_msgs/Odometry & Publica la odometría\\
{\bf Parámetros} & {\bf Tipo} & {\bf Descripción}\\
\hline
port & string & Puerto serie del robot\\
TicksMM & float & Calibración de la odometría\\
DriftFactor & float & Rozamiento de la odometría\\
RevCount & float & Calibración de los encoders\\
{\bf Frames publicados} &  & {\bf Descripción}\\
\hline
base\_link & & Referencia base del robot\\
odom & & Referencia odométrica
\end{tabular}
}
\caption{API de \textit{rosaria} utilizada. Basado en \cite{rosaria}.}
\label{tabla_rosaria}
\end{table}

\end{itemize}

\subsection{Sensor Kinect}\label{subsection:kinect}

Para la puesta en marcha del sensor Kinect existen en ROS diferentes paquetes que utilizan una u otra librería de código en función de quién lo hayade sarrollado.

Existen dos paquetes destinados al control del sensor Kinect:

Por un lado tenemos \textit{openni\_kinect} **referencia**, que utiliza los drivers de la librería OpenNI **REFERENCIA**. Este paquete y en concreto los drivers del dispositivo han sido utilizados ampliamente tanto en desarrollos realizados con ROS como fuera de este entorno. Sus características principales son la total funcionalidad, aprovechamiento de toda la tecnología de este sensor y capacidad para monitorear la posición del esqueleto de una persona. Sin embargo, el soporte del paquete \textit{openni\_kinect} solo se mantuvo activo hasta a versión ROS Fuerte **referencia** debido a la compra de PrimeSense, empresa creadora del sensor y miembro fundador del proyecto OpenNI, por la conocida marca de informática Apple \cite{appleprimesense}.

Por otro lado, gracias al gran desarrollo software llevado a cabo por la comunidad OpenSource, disponemos de los divers \textit{libfreenect} desarrollados por el proyecto OpenKinect \url{http://openkinect.org/wiki/Main_Page} que trata de ofrecer una vía alternativa para controlar el sensor de Microsoft. Estos drivers se encapsulan y adaptan su interfaz a ROS a través del paquete \textit{freenect\_stack} **referencia** el cual nos ofrece acceso tan solo a la imagen y la nube de puntos del sensor. Su integración no es completa, no dispone de características adicionales como el monitoreo de la posición de una persona, sin embargo su funcionamiento es correcto y está adaptado a ROS en su versión Indigo y esto nos ofrece la posibilidad de integrarlo en nuestro sistema. Por estas razones ha sido el software utilizado para acceder al sensor Kinect en este proyecto. \textit{freenect\_stack}, al ser un paquete de terceros, debe clonarse desde su repositorio de código fuente e incorporarlo a nuestro entorno Catkin.

Su puesta en marcha es bastante inmediata y podemos hacer uso de los \textit{launchfiles} que ofrece \textit{freenect\_launch} desde consola de la siguiente forma:

\begin{code}[htp]
\begin{lstlisting}[style=consola]
roslaunch freenect_launch freenect.launch
\end{lstlisting}
\hypersetup{urlcolor=black}
Fuente: \href{https://github.com/ros-drivers/freenect_stack/blob/master/freenect_launch/launch/freenect.launch}{\textit{freenect\_stack/freenect\_launch/launch/freenect.launch}}
\hypersetup{urlcolor=blue}
\caption{Launchfile para Kinect en el paquete freenect\_launch.}
\end{code}

En la tabla \ref{tabla_freenect} se muestra parte de la API utilizada.

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c}
& {\bf libfreenect\_stack API} & \\
{\bf Topics publicados} & {\bf Mensaje} & {\bf Descripción}\\
\hline
camera/depth/points & sensor\_msgs/PointCloud2 & Publica la nube de puntos\\
camera/depth/image\_raw & sensor\_msgs/Image & Imagen captada\\
camera/depth/camera\_info & sensor\_msgs/CameraInfo & Información de la cámara\\
{\bf Frames} &  & {\bf Descripción}\\
\hline
camera\_link & & Referencia base de Kinect\\
camera\_rgb\_frame & & Referencia cámara RGB\\
camera\_depth\_frame & & Referencia cámara IR\\
\end{tabular}
}
\caption{API de freenect\_stack utilizada.}
\label{tabla_freenect}
\end{table}

\subsection{Sensor Láser Sick LMS100}\label{subsection:sicklms100}

Existe un amplio soporte para sensores láser de la marca Sick, entre ellos el más popular es la familia Sick LMS200 ya que se utiliza en muchos desarrollos relacionados con la robótica móvil **referencia**. Esa familia de sensores utiliza una interfaz de comunicación en serie a través de puerto RS-232, sin embargo, la familia de dispositivos Sick LMS100 utiliza interfaz ethernet y requiere un tratamiento de datos diferente.

El láser Sick LMS100 ha sido integrado en ROS y utilizado en este proyecto ya que se había dado uso en proyectos anteriores **referencia alejandro** y se consideró conveniente incorporarlo y utilizarlo para obtener una navegación más precisa del robot.

Para acceder al sensor Sick LMS100 utilizamos el paquekte \textit{LMS1xx} desarrollado por Clearpath Robotics **referencia** que se basa en el trabajo de otros dos desarrolladores de la comunidad ROS, y en concreto en los drivers desarrollados por **referencia** https://github.com/konradb3/libLMS1xx

El paquete \textit{LMS1xx} consta de un solo nodo que se conecta a través de una IP indicada como parámetro. Para conectarnos al sensor láser es necesario configurar el puerto del ordeandor con una IP fija dentro del mismo rango que la IP del sensor, la puerta de enlace queda vacía y utilizamos la máscara de subred por defecto.

Seguidamente basta con indicar en el archivo \textit{launchfile} la IP del sensor.

\begin{code}[htp]
\begin{lstlisting}[style=launch]
<launch>
  <arg name="host" default="192.168.1.14" />
  <node pkg="lms1xx" name="lms1xx" type="LMS1xx_node">
    <param name="host" value="$(arg host)" />
  </node>
</launch>
\end{lstlisting}
\hypersetup{urlcolor=black}
Fuente: \href{https://github.com/clearpathrobotics/LMS1xx/blob/master/launch/LMS1xx.launch}{\textit{LMS1xx/launch/LMS1xx.launch}}
\hypersetup{urlcolor=blue}
\caption{Launchfile para el sensor Láser Sick LMS100.}
\end{code}

Pueden precisarse algunos ajustes previos con la herramienta que ofrece el fabricante "SOPAS Engineering tool", los cuales pueden encontrarse en el apéndice de este trabajo (Sección \ref{subsection:sicklms100_apendice}).

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c}
& {\bf LMS1xx API} & \\
{\bf Topics publicados} & {\bf Mensaje} & {\bf Descripción}\\
\hline
/scan & sensor\_msgs/LaserScan & Puntos láser\\
{\bf Parámetros} & {\bf Tipo} & {\bf Descripción}\\
\hline
host & string & Dirección IP del láser\\
{\bf Frames} &  & {\bf Descripción}\\
\hline
laser & & Centro del haz láser\\
\end{tabular}
}
\caption{API de LMS1xx utilizada.}
\label{tabla_lms1xx}
\end{table}

\url{http://wiki.ros.org/LMS1xx}

\subsection{Integración del hardware}\label{subsection:integracion_hardware}

Una vez disponemos de todos los paquetes necesarios para poner en funcionamiento todo el hardware en el robot, necesitamos integrar todos los nodos bajo una misma configuración y definir mediante transformadas la posición de los sensores en el robot.

Es necesario por tanto crear un nuevo archivo launchfile (Código \ref{code:pioneer3at-rosaria})desde el cual lanzar cada nodo con las configuraciones del hardware y definir transformadas estáticas entre cada uno de los \textit{frames}.

\begin{code}[htp]
\begin{lstlisting}[style=launch]
<launch>

<!-- Launching p2os RobotModel --> OJO!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  <include file="$(find p2os_urdf)/launch/pioneer3at_urdf.launch"/>

<!-- Launching LMS1xx_node for laser Sick LMS100 via ethernet -->
  <include file="$(find pioneer_utils)/sensors/LMS1xx.launch"/>

<!-- start sensor-->
<include file="$(find freenect_launch)/launch/freenect.launch"/>

<!-- Launch kinect and depthimage_to_laser node -->
  <include file="$(find pioneer_utils)/sensors/kinect_to_laser_low.launch"/>

<!-- Launch kinect and depthimage_to_laser node -->
  <include file="$(find pioneer_utils)/sensors/kinect_to_laser.launch"/>

<!-- Starting rosaria driver for motors and encoders -->
  <include file="$(find pioneer_utils)/sensors/rosaria.launch"/>

  <node pkg="tf" type="static_transform_publisher" name="base_to_laser_broadcaster" args="-0.2 0 0.390 3.141592 0 0 base_link laser 1" />
  <node pkg="tf" type="static_transform_publisher" name="base_to_camera_broadcaster" args="0.020 0 0.375 0 0 0 base_link camera_link 1" />

</launch>
\end{lstlisting}
\hypersetup{urlcolor=black}
Fuente: \href{https://github.com/danimtb/pioneer3at_ETSIDI/blob/master/pioneer_utils/sensors/pioneer3at-rosaria.launch}{\textit{pioneer\_utils/sensors/pioneer3at-rosaria.launch}}
\hypersetup{urlcolor=blue}
\caption{Launchfile creado para robot Pioneer 3 AT.}
\label{code:pioneer3at-rosaria}
\end{code}

Como resultado, obtenemos una relación entre cada sistema de coordenadas (\textit{frame}) y podemos realizar cálculos entre cada uno de ellos. Esto también sirve para que el robot "sea consciente" de su configuración.

\begin{figure}[htp]
\centering
\includegraphics[width=0.8\textwidth]{figuras/frames-odom_base.png}
\caption{Referencias \textit{frames} de la configuración del robot.}
\label{fig:frames-odom_base}
\end{figure}

\section{Nodo de teleoperación}

Uno de los primeros objetivos de este proyecto es realizar el control teleoperado del robot. Utilizando ROS y sus características para operar de manera distribuida en diferentes máquinas, esta tarea se vuelve inmediata para el usuario.

ROS trabaja en forma de procesos que se ejecutan de manera independiente y se comunican a través del nodo principal o Máster con el paso de mensajes. Ya que el máster dispone de una dirección IP en la máquina que lo ejecuta, basta con indicar en el entorno ROS de cada máquina la dirección de este para que los nodos abran una comunicación con esa dirección IP.

Los pasos para configurar las máquinas bajo la misma red se describen con detalle en la guía ROS NETWORKING y consisten básicamente en indicar en el sript \textit{.bashrc} el parámetro ROS	\_IP y ROS\_MASTER\_URI.

ROS\_IP debe contener la IP que tenga nuestra máquina en la red que esté operando y ROS\_MASTER\_URI la dirección \textit{http} correspondiente de la máquina donde se ejecute el nodo principal.

\begin{code}[htp]
\begin{lstlisting}[style=launch]
export ROS_IP=10.42.0.1
export ROS_MASTER_URI=http://10.42.0.1:11311
\end{lstlisting}
Fuente: \textit{$\sim$/.bashrc}
\caption{Líneas del archivo \textit{.bashrc} en el ordenador de abordo.}
\end{code}

\begin{code}[!htp]
\begin{lstlisting}[style=launch]
export ROS_IP=10.42.0.77
export ROS_MASTER_URI=http://10.42.0.1:11311
\end{lstlisting}
Fuente: $\sim$\textit{/.bashrc}
\caption{Ejemplo \textit{.bashrc} en un ordenador externo para realizar comunicación con el máster.}
\end{code}

De esta manera podemos desarrollar un nodo ROS que se conecte al topic de RosAria que comanda los motores \textit{cmd\_vel} y publicar diferentes valores de velocidad en función de las teclas que se pulsen.

\begin{code}[htp]
\begin{lstlisting}[style=C++]	
}
\end{lstlisting}
Fuente: $\sim$\textit{/.bashrc}
\caption{Ejemplo \textit{.bashrc} en un ordenador externo para realizar comunicación con el máster.}
\end{code}

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c}
& {\bf teleop\_p3at API} & \\
{\bf Topics publicados} & {\bf Mensaje} & {\bf Descripción}\\ \hline
cmd\_vel & geometry\_msgs/Twist & Publica comandos de velocidad\\
\end{tabular}
}
\caption{API de teleop\_p3at}
\label{tabla:teleop_p3at}
\end{table}

\section{Nodo de navegación estimada}

La navegación estimada, más conocida en inglés como Dead Reckoning \cite{deadreckoning}, es la capacidad para realizar navegación en un entorno basándonos solamente en la información que aportan los sensores de la odometría.

Es un método estimado de localización que se basa en la información de los encoders y no tiene en cuenta aspectos como el tipo de superficie, la inclinación, el rozamiento o incluso obstáculos que puedan frenar o modificar el desplazamiento del robot (a pesar de que sus ruedas giren).

Este nodo de navegación puede utilizarse para indicar al robot que avance cierta cantidad de metros y que realice giros a derecha o izquierda en un determinado ángulo.

**Fragmento de código**

\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c}
& {\bf moving\_alone API} & \\
{\bf Topics suscritos} & {\bf Mensaje} & {\bf Descripción}\\ \hline
pose & nav\_msgs/Odometry & Recibe la odmetría\\
{\bf Topics publicados} & {\bf Mensaje} & {\bf Descripción}\\ \hline
cmd\_vel & geometry\_msgs/Twist & Publica comandos de velocidad\\
{\bf Frames suscritos} &  & {\bf Descripción}\\
\hline
base\_link & & Referencia base del robot\\
odom & & Referencia odométrica
\end{tabular}
}
\caption{API de moving\_alone}
\label{tabla:moving_alone}
\end{table}