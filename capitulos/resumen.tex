\selectlanguage{spanish}

%chapter introduce un nuevo capítulo
\chapter{Resumen}

Realizar la navegación y guiado de un robot móvil surge como herramienta para acceder a lugares donde el ser humano no puede o se encontraría en riesgo, para realizar tareas repetitivas o que conllevasen algún tipo de desgaste.\\

Un robot autónomo es por tanto una pieza fundamental en tareas de rescate, salvamento, inspección, exploración de entornos peligrosos o inaccesibles, como la exploración en la superficie de otros planetas. Además, las tareas sociales cada vez están tomando más relevancia en nuestro día a día, como la asistencia a humanos en entornos públicos, la interección con el entorno o una navegación más segura, como es el caso de los coches autónomos.\\

Este proyecto de fin de grado trata sobre el guiado y control de un robot móvil de cuatro ruedas, con un sistema motriz en configuración diferencial, equipado con una serie de sensores que permiten su orientación y posicionado en el entorno así como un sensor capaz de captar este en tres dimensiones y un sensor adicional que lo haría tan solo en dos dimensiones.\\

Los datos de los sensores sirven tanto para construir mapas en dos dimensiones del entorno del robot como para navegar por él evitando obstáculos de manera dinámica. El robot es capaz de generar mapas de celdas en los que situar tanto los objetos estáticos como los móviles, calcular una trayectoria adecuada y dirigirse hasta un punto indicado evitando obstáculos interpuestos en su camino.\\

Todo esta información, procesado de datos, cálculo de trayectorias y ejecución de movimientos se realiza en un ordenador de abordo integrado en el propio robot utilizando el software Robot Operating System (conocido en robótica por sus siglas ROS), que nos ofrece una interfaz común para interconectar nuestro robot con los sensores y con los algoritmos de navegación.\\

El proceso de navegación se realiza de dos formas conjuntamente. Por un lado el robot realiza un mapa global con obstáculos que permanecen inmóviles y calcula la trayectoria más adecuada, es lo que denominamos navegación global. Por otro lado, el robot genera un mapa dinámico a su alrededor e identifica la información de los sensores como obstáculos, a continuación, el robot calcula continuamente una trayectoria que se ajuste todo lo posible a la trayectoria global pero que evite los obstáculos cercanos, es lo que se denomina navegación reactiva o local.\\

Finalmente, un algoritmo de cálculo de movimientos realiza el control de los motores para que el robot realice el movimiento adecuado en base a las trayectorias definidas anteriormente. De esta forma el robot puede avanzar, retroceder, darse la vuelta o realizar tareas de recuperación de trayectoria en caso de encontrarse bloqueado en algún punto.\\

A parte de la navegación autónoma, también dispone de un sitema de telecontrol del robot mediante otro ordenador  externo y de un algoritmo de detección frontal de objetos en 3 dimensiones (nubes de puntos) que puedan servirle como guía. De esta forma, el robot es capaz de navegar siguiendo el movimiento de una persona o de un robot que le preceda.\\

El robot Pioneer 3 AT es el robot móvil que se ha empleado en este proyecto (Figura \ref{fig:esquema_robot}) y sobre el que se ha trabajado de manera específica para realizar las pruebas reales de este proyecto. A este robot se le incorporan un sensor láser de dos dimensiones (sensor Sick LMS100) y un sensor de tres idmensiones (sensor Kinect). El cómputo de la navegación se realiza en un ordenador compacto incorporado en el robot (ordenador Intel NUC ***).\\


\begin{figure}[htp]
\centering
\includegraphics[width=0.8\textwidth]{figuras/esquema_robot.jpg}
\caption{Esquema del sistema robótico utilizado en el proyecto} \label{fig:esquema_robot}
\end{figure}

Las consignas de navegación se realizan mediante un ordenador externo cualquiera conectado a una red inalámbrica o mediante consignas de voz, en las que se indica al robot las tareas de navegación a realizar (avanzar, girar, seguir a una persona...) o un punto del entorno al que dirigirse.\\

Todas estas implementaciones están desarrolladas bajo el entorno ROS, lo cual permite añadir funcionalidades de manera más rápida y menos laboriosa, como es el caso del control mediante comandos de voz o la interacción mediante sonidos. Es el caso también del simulador de robótica Gazebo, que se integra como funcionalidad en ROS y que ha servido para testear el sistema y aportar las pruebas teóricas pertinentes para luego aplicarlas en el robot real.\\

Para concluir, podemos decir que este proyecto se encarga de integrar ROS como sistema en un ordenador de abordo incorporado en el robot que permita conectarse con los sensores y realizar la construcción de mapas y navegación autónoma mediante el cáculo de mapas y trayectorias globales y locales, realizar los movimientos del robot, así como reconocer consignas de voz o de teleoperación.

\paragraph{Palabras clave:} palabraclave1, palabraclave2, palabraclave3.

\selectlanguage{USenglish}
\chapter{Abstract}

Achieving navigation and guidance of mobile robot comes up as a tool for rescue purposes in places where humans can't access or that involve a high risk for life. Many of those repetitive and fatigating tasks could be done with a robust and capable mobile robot.\\

An autonomous robot is, by the way, an essential part in rescue, inspection and exploration tasks developed in dangerous or non-reacheable places, such as the surface of other planets. Moreover, social tasks are taking more and more interest in our nowadays, such as assitance for humans in pubic places, interaction with the environment or a safer navigation in the cities. Autonomous car navigtion is a good example of this.\\

This final degree project is about guidance and control of a four-wheel mobile robot with a skid-steer configuration. It is equipped with a sort of sensors, allowing it to make positioning and orientation in the environment. There is also a main sensor capturing the enviaronment en three dimension and an additional one doing it in two dimensions.\\

Sensor data is used to build two dimensional maps of the exploration place as well as to take care of dynamical obstacles. The robot can build maps formed by cells where to incorpore or raytrace static and dynamic obstacles, calculate the proper trajectory plan and head for a destination point avoiding obstacles in its way.\\

All this information, data processing, trajectory calculation and movement execution is done in an onboard computer inside the robot. It uses the Robot Operating System software (known as ROS), which offers a commmon interface to communicate the robot with sensors and navigation algorithms.\\

The navigation process is divided in two parts. Firstly, a global obstacle map is done and static objects are addded, then the most suitable trajectory is planned. This is called global navigation. Secondly, a dynamic map is done and sensor data incorpores obstacles near the robot. Immediatly, a possible trajectory is planned following the original trajectory of the global navigation but avoiding the obstacles. This is called reactive or local navigation.\\

Finally, a movement algorithm does the control over the robot. It calculates movements to make the robot go forward, backward, turn around or make recovery tasks to recover if the robot has lost the trajectory path or it is stucked at any point.\\

Apart from autonomous navigation, the robot also has a telecontrol system from an outside computer and an algorithm to detect frontal objects in three dimensions (pointclouds) that can guide the robot. This is how it can navigate following a person when it is walking or another robot in front of it.\\

Pioneer 3 AT robot is the one used in this project (Figure \ref{fig:esquema_robot}). It is the specific platform and all real tests have been made with it. This robots is equipped with a two dimension laser scanner (Sick LMS100 sensor) and a three dimensional sensor (Kinect sensor). The navigation computation is done in an onboard compact computer (Intel NUC *** computer).\\

\begin{figure}[htp]
\centering
\includegraphics[width=0.8\textwidth]{figuras/esquema_robot.jpg}
\caption{Diagram of the robotic system used for this project} \label{fig:esquema_robot}
\end{figure}

The navigation commands are sent from an outside computer connected to the same wireless network or from voice navigatin commands speaking directly to the robot (go forward, backward, turn right...) or a point in the map to move forward.\\

All those implementations are developed under ROS framework. This is why additional features can be added in a faster and effortless way. Tha is the case of the robot simlator Gazebo, which integrates as an add-on in ROS. Gazebo has been used to perform tests in navigation and to check theorical concepts to lately incorporate them in the real robotic system.\\

To conclude, it can be said that this project integrates ROS as a robotic system in an onboard computer and connects to sensors to perform tasks such as building maps or navigation from one point to other. The system calculates local and global maps and trajectories, makes movements according to them, as well as recognises voice or teleoperation commands.\\

\paragraph{Palabras clave:} PalabraClave1, keyword2, keyword3.

\selectlanguage{spanish}