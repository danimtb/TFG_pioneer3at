\selectlanguage{spanish}

%chapter introduce un nuevo capítulo
\chapter{Resumen}

Muchos robots autónomos surgen como herramienta para acceder a lugares donde el ser humano no puede o no conviene que acceda porque se encontraría en riesgo.

Un robot autónomo es por tanto una pieza fundamental en tareas de rescate, salvamento, inspección, exploración de entornos peligrosos o inaccesibles, como la exploración en la superficie de otros planetas. Además, tareas sociales como la asistencia a humanos en entornos públicos, la interacción con el entorno o una navegación más segura, como es el caso de los coches autónomos, cada vez están tomando más relevancia en nuestro día a día.

Este proyecto de fin de grado trata sobre el guiado y control de un robot móvil de cuatro ruedas, con un sistema motriz en configuración skid-steer, equipado con una serie de sensores que permiten su orientación y posicionado en el entorno así como un sensor capaz de captar este en tres dimensiones y un sensor adicional que lo hace tan solo en dos dimensiones.

Los datos de los sensores sirven tanto para construir mapas en dos dimensiones del entorno del robot como para navegar por él evitando obstáculos de manera dinámica. El robot es capaz de generar mapas de celdas en los que situar tanto los objetos estáticos como los móviles, calcular una trayectoria adecuada y dirigirse hasta un punto indicado evitando obstáculos interpuestos en su camino.

Todo esta información, procesado de datos, cálculo de trayectorias y ejecución de movimientos se realiza en un ordenador de abordo integrado en el propio robot utilizando el software Robot Operating System (conocido en robótica por sus siglas ROS), que nos ofrece una interfaz común para interconectar nuestro robot con los sensores y con los algoritmos de navegación.

A parte de la navegación autónoma, también se ha incluido un sistema de telecontrol del robot mediante otro ordenador  externo y de un algoritmo de detección frontal de objetos en 3 dimensiones (nubes de puntos) que puedan servirle como guía. De esta forma, el robot es capaz de navegar siguiendo el movimiento de una persona o de un robot que le preceda.

El robot Pioneer 3 AT es el robot móvil que se ha empleado en este proyecto (Figura \ref{fig:esquema_robot1}) y sobre el que se ha trabajado de manera específica para realizar las pruebas reales de este proyecto. A este robot se le incorporan un sensor láser de dos dimensiones (sensor Sick LMS100) y un sensor de tres dimensiones (sensor Kinect). El cómputo de la navegación se realiza en un ordenador compacto incorporado en el robot (Intel NUC NUC5i7RYH).


\begin{figure}[htp]
\centering
\includegraphics[width=0.8\textwidth]{figuras/esquema_robot.jpg}
\caption{Esquema del sistema robótico utilizado en el proyecto} \label{fig:esquema_robot1}
\end{figure}

Las consignas de navegación se realizan mediante un ordenador externo cualquiera conectado a una red inalámbrica o mediante consignas de voz, en las que se indica al robot las tareas de navegación a realizar (avanzar, girar, seguir a una persona...) o un punto del entorno al que dirigirse.

Todas estas implementaciones están desarrolladas bajo el entorno ROS, lo cual permite añadir funcionalidades de manera más rápida y menos laboriosa, como es el caso del control mediante comandos de voz o la interacción mediante sonidos. Es el caso también del simulador de robótica Gazebo, que se integra como funcionalidad en ROS y que ha servido para testar el sistema y aportar las pruebas teóricas pertinentes para luego aplicarlas en el robot real.

Para concluir, podemos decir que este proyecto se encarga de integrar ROS como sistema en un ordenador de a bordo incorporado en el robot que permita conectarse con los sensores y realizar la construcción de mapas y navegación autónoma mediante el cáculo de mapas y trayectorias globales y locales, realizar los movimientos del robot, así como reconocer consignas de voz o de teleoperación.

\paragraph{Palabras clave:} robot móvil, ROS, navegación reactiva, cálculo de trayectorias.

\chapter{Abstract}

Achieving navigation and guidance of mobile robot comes up as a tool for rescue purposes in places where humans can't access or that involve a high risk for life. Many of those repetitive and fatigating tasks could be done with a robust and capable mobile robot.

An autonomous robot is, an essential part in rescue, inspection and exploration tasks developed in dangerous or non-reacheable places, such as the surface of other planets. Moreover, social tasks such as assitance for humans in pubic places, interaction with the environment or a safer navigation in the cities. Autonomous cars are a good example of this.

This final degree project is about guidance and control of a four-wheel mobile robot with a skid-steer configuration. It is equipped with a sort of sensors, allowing it to make positioning and orientation in the environment. There is also a main sensor capturing the enviaronment in three dimensions and an additional one doing it in two dimensions.

Sensor data is used to build two dimensional maps of the exploration place as well as to take care of dynamical obstacles. The robot can build maps formed by cells where to incorpore or raytrace static and dynamic obstacles, calculate the proper trajectory plan and head for a destination point avoiding obstacles in its way.

All this information, data processing, trajectory calculation and movement execution is done in an onboard computer inside the robot. It uses the Robot Operating System software (known as ROS), which offers a commmon interface to communicate the robot with sensors and navigation algorithms.

Apart from autonomous navigation, the robot also has a telecontrol system from an outside computer and an algorithm to detect frontal objects in three dimensions (pointclouds) that can guide the robot. This is how it can navigate following a person when it is walking or another robot in front of it.

Pioneer 3 AT robot is the one used in this project (Figure \ref{fig:esquema_robot2}). It has been the specific platform for all real tests. This robot is equipped with a two dimension laser scanner (Sick LMS100 sensor) and a three dimensional sensor (Kinect sensor). The navigation computation is done in an onboard compact computer (Intel NUC NUC5i7RYH computer).

\begin{figure}[htp]
\centering
\includegraphics[width=0.8\textwidth]{figuras/esquema_robot.jpg}
\caption{Diagram of the robotic system used for this project} \label{fig:esquema_robot2}
\end{figure}

The navigation commands are sent from an outside computer connected to the same wireless network or from voice navigation commands speaking directly to the robot (go forward, backward, turn right...) or pointing a goal in the map.

All those implementations are developed under ROS framework. This is why additional features can be added in a faster and effortless way. Tha is the case of the robot simlator Gazebo, which integrates as an add-on in ROS. Gazebo has been used to perform tests in navigation and to check theorical concepts to lately incorporate them in the real robotic system.

To conclude, it can be said that this project integrates ROS as a robotic system in an onboard computer and connects to sensors to perform tasks such as building maps or navigation from one point to another. The system calculates local and global maps and trajectories, makes movements according to them, as well as recognises voice or teleoperation commands.

\paragraph{Keywords:} mobile robot, ROS, reactive navigation, trajectory calculation.